# <h1 align="center">:star2: Speech Recognition Papers :star2:</h1>
  
<p align=center><i> End-to-End, Listen-Attend-Spell, Speech-Transformer, RNN-Transducer </i></p>  

* \[2006/08\] [**CTC**](https://www.cs.toronto.edu/~graves/icml_2006.pdf) : S
  
* \[2012/11\] [**Sequence Transduction with Recurrent Neural Networks**](https://arxiv.org/abs/1211.3711)   : J
  
* \[2015/08\] [**Listen, Attend and Spell**](https://arxiv.org/abs/1508.01211) : Y

* \[2017/06\] [**Joint CTC Attention**](https://arxiv.org/pdf/1609.06773.pdf) : KY

* \[2017/06\] [**Advances in Joint CTC-Attention based E2E ASR with a Deep CNN Encoder and RNN-LM**](https://arxiv.org/abs/1706.02737) : Y
  
* \[2017/07\] [**Attention Is All You Need**](https://arxiv.org/abs/1706.03762)   
  
* \[2017/12\] [**State-of-the-art Speech Recognition with Sequence-to-Sequence Models**](https://arxiv.org/abs/1712.01769)  : J
  
* \[2017/12\] [**An Analsis Of Incorporating An External Language Model Into A Sequence-to-Sequence Model**](https://arxiv.org/abs/1712.01996)  :   KY

* \[2018/02\] [**MONOTONIC CHUNKWISE ATTENTION**](https://arxiv.org/pdf/1712.05382.pdf)  :  Y
  
* \[2018/04\] [**Speech-Transformer: A No-Recurrence Sequence-to-Sequence Model for Speech Recognition**](https://ieeexplore.ieee.org/document/8462506)  
  
* \[2019/02\] [**On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition**](https://arxiv.org/abs/1902.01955)  
  
* \[2019/04\] [**wav2vec: Unsupervised Pre-training for Speech Recognition**](https://arxiv.org/abs/1904.05862?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%253A+arxiv%252FQSXk+%2528ExcitingAds%2521+cs+updates+on+arXiv.org%2529)  
  
* \[2019/05\] [**Transformers with convolutional context for ASR**](https://arxiv.org/abs/1904.11660)  
  
* \[2019/08\] [**Jasper: An End-to-End Convolutional Neural Acoustic Model**](https://arxiv.org/pdf/1904.03288.pdf)  
  
* \[2019/11\] [**End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern Architectures**](https://arxiv.org/abs/1911.08460)  
  
* \[2020/05\] [**ContextNet: Improving Convolutional Neural Networks for ASR with Global Context**](https://arxiv.org/abs/2005.03191)  
  
* \[2020/05\] [**Conformer: Convolution-augmented Transformer for Speech Recognition**](https://arxiv.org/abs/2005.08100)  
  
* \[2020/06\] [**wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations**](https://arxiv.org/abs/2006.11477)

* \[2022/12\] [**Robust Speech Recognition via Large-Scale Weak Supervision (Whisper)**](https://arxiv.org/pdf/2212.04356.pdf)

# <h2 align="center"> Spoken Language Understanding Papers </h2>

* \[2022/07\] [**Integration of Pre-trained Networks with Continuous Token Interface for End-to-end Spoken Language Understanding**](https://arxiv.org/pdf/2104.07253.pdf)
